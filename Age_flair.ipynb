{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_flair.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4xhHJc96fQM"
      },
      "source": [
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from numpy import array\n",
        "from numpy import mean \n",
        "#import guidedlda"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2hPHi3H7Fru",
        "outputId": "e910a637-91ff-470d-8a47-fad6aa4ca80f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veVbEHDN7LNa"
      },
      "source": [
        "age_df = pd.read_csv('/content/drive/MyDrive/CS640/final_project/preprocessed_tweets_with_for_age_pred.csv',  lineterminator='\\n')\n",
        "## drop NaN\n",
        "age_df.dropna(inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62dOaLSp8Q_q"
      },
      "source": [
        "## sample from age_df\n",
        "freq = pd.DataFrame({'label':[0, 1],\n",
        "                     'nostoextract':[36115, 36115], })\n",
        "def bootstrap(data, freq):\n",
        "    freq = freq.set_index('label')\n",
        "\n",
        "    # This function will be applied on each group of instances of the same\n",
        "    # class in `data`.\n",
        "    def sampleClass(classgroup):\n",
        "        cls = classgroup['label'].iloc[0]\n",
        "        nDesired = freq.nostoextract[cls]\n",
        "        nRows = len(classgroup)\n",
        "\n",
        "        nSamples = min(nRows, nDesired)\n",
        "        return classgroup.sample(nSamples)\n",
        "\n",
        "    samples = data.groupby('label').apply(sampleClass)\n",
        "\n",
        "    # If you want a new index with ascending values\n",
        "    # samples.index = range(len(samples))\n",
        "\n",
        "    # If you want an index which is equal to the row in `data` where the sample\n",
        "    # came from\n",
        "    samples.index = samples.index.get_level_values(1)\n",
        "\n",
        "    # If you don't change it then you'll have a multiindex with level 0\n",
        "    # being the class and level 1 being the row in `data` where\n",
        "    # the sample came from.\n",
        "\n",
        "    return samples\n",
        "\n",
        "sampled_age_df = bootstrap(age_df,freq)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0PSPMA_8TnC"
      },
      "source": [
        "## stem \n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOrbqiAb9kiB"
      },
      "source": [
        "stem_list = []\n",
        "for txt in sampled_age_df['text']:\n",
        "    wrds = txt.split()\n",
        "    stem_wrds = []\n",
        "    \n",
        "    for i in wrds:\n",
        "        stem_wrds.append(stemmer.stem(i))\n",
        "    \n",
        "    str1 = ' '.join(stem_wrds)  \n",
        "    stem_list.append(str1)\n",
        "\n",
        "sampled_age_df['text'] = stem_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB7f0vDv9oSX",
        "outputId": "ffa09811-ab83-4dc7-afdc-1abbcd2097d9"
      },
      "source": [
        "sampled_age_df['label'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    36115\n",
              "0    36115\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN29L9Wq91wR"
      },
      "source": [
        "!pip install allennlp==0.9.0.\n",
        "!pip install flair==0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS2y1eyd-N7j"
      },
      "source": [
        "from torch.optim.adam import Adam\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ClassificationCorpus\n",
        "from pathlib import Path\n",
        "from flair.data import Sentence\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.embeddings import TransformerDocumentEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings, BertEmbeddings, WordEmbeddings, DocumentRNNEmbeddings, ELMoEmbeddings"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uzfaMWd1AGZx",
        "outputId": "5fe6b9d9-b719-4efd-b16b-cde5808f1c9c"
      },
      "source": [
        "sampled_age_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>screen_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78622</th>\n",
              "      <td>91672</td>\n",
              "      <td>pleas don touch raf</td>\n",
              "      <td>0</td>\n",
              "      <td>alli33s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82990</th>\n",
              "      <td>97057</td>\n",
              "      <td>weak for sure thank gabe miss you</td>\n",
              "      <td>0</td>\n",
              "      <td>MaiaBica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17570</th>\n",
              "      <td>19594</td>\n",
              "      <td>wa said didnt realiz</td>\n",
              "      <td>0</td>\n",
              "      <td>ay_p329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66226</th>\n",
              "      <td>76484</td>\n",
              "      <td>fact</td>\n",
              "      <td>0</td>\n",
              "      <td>mekaylaap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8781</th>\n",
              "      <td>9753</td>\n",
              "      <td>you can play the guitar solo hotel california ...</td>\n",
              "      <td>0</td>\n",
              "      <td>caro_number7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51952</th>\n",
              "      <td>59441</td>\n",
              "      <td>just post photo</td>\n",
              "      <td>1</td>\n",
              "      <td>Queen_Miasma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43595</th>\n",
              "      <td>49548</td>\n",
              "      <td>dad ask still keep contact with paramor how da...</td>\n",
              "      <td>1</td>\n",
              "      <td>koolkatkrystal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4717</th>\n",
              "      <td>5227</td>\n",
              "      <td>thi deadass wa dure the georgia trip</td>\n",
              "      <td>1</td>\n",
              "      <td>eccentric_mia_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15307</th>\n",
              "      <td>17007</td>\n",
              "      <td>thi sexi bitch keep bloom</td>\n",
              "      <td>1</td>\n",
              "      <td>nicholaslee137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35133</th>\n",
              "      <td>39656</td>\n",
              "      <td>depend onc fine after wrap</td>\n",
              "      <td>1</td>\n",
              "      <td>gizzz23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72230 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...     screen_name\n",
              "78622       91672  ...         alli33s\n",
              "82990       97057  ...        MaiaBica\n",
              "17570       19594  ...         ay_p329\n",
              "66226       76484  ...       mekaylaap\n",
              "8781         9753  ...    caro_number7\n",
              "...           ...  ...             ...\n",
              "51952       59441  ...    Queen_Miasma\n",
              "43595       49548  ...  koolkatkrystal\n",
              "4717         5227  ...  eccentric_mia_\n",
              "15307       17007  ...  nicholaslee137\n",
              "35133       39656  ...         gizzz23\n",
              "\n",
              "[72230 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S6yoCv2E_BXx",
        "outputId": "56e00a5d-bc56-4f07-d6d9-e8128862c1f2"
      },
      "source": [
        "sampled_age_df = sampled_age_df.drop(columns=['Unnamed: 0', 'screen_name'])\n",
        "sampled_age_df['label'] = '__label__' + sampled_age_df['label'].astype(str)\n",
        "random = sampled_age_df.sample(frac=1)\n",
        "random"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>goddess</td>\n",
              "      <td>__label__0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76029</th>\n",
              "      <td>never end cycl too</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82705</th>\n",
              "      <td>mayb thi can help</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64925</th>\n",
              "      <td>you ever see thi love you and wish you the best</td>\n",
              "      <td>__label__0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71010</th>\n",
              "      <td>thi same teacher who also chang her grade poli...</td>\n",
              "      <td>__label__0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40793</th>\n",
              "      <td>there profession turn the wind encourag you mo...</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92414</th>\n",
              "      <td>betray own dog</td>\n",
              "      <td>__label__0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24757</th>\n",
              "      <td>lmfao</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40530</th>\n",
              "      <td>noth cure hangov like svu marathon</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31931</th>\n",
              "      <td>the experi cycl whi mentor import</td>\n",
              "      <td>__label__1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72230 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text       label\n",
              "196                                              goddess  __label__0\n",
              "76029                                 never end cycl too  __label__1\n",
              "82705                                  mayb thi can help  __label__1\n",
              "64925    you ever see thi love you and wish you the best  __label__0\n",
              "71010  thi same teacher who also chang her grade poli...  __label__0\n",
              "...                                                  ...         ...\n",
              "40793  there profession turn the wind encourag you mo...  __label__1\n",
              "92414                                     betray own dog  __label__0\n",
              "24757                                              lmfao  __label__1\n",
              "40530                 noth cure hangov like svu marathon  __label__1\n",
              "31931                  the experi cycl whi mentor import  __label__1\n",
              "\n",
              "[72230 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xSC_CvAs3i"
      },
      "source": [
        "random.iloc[0:int(len(random)*0.8)].to_csv('/content/drive/MyDrive/CS640/final_project/age_train.csv', sep='\\t', index = False, header = False, columns=['label', 'text'])\n",
        "random.iloc[int(len(random)*0.8):int(len(random)*0.9)].to_csv('/content/drive/MyDrive/CS640/final_project/age_test.csv', sep='\\t', index = False, header = False, columns=['label', 'text'])\n",
        "random.iloc[int(len(random)*0.9):].to_csv('/content/drive/MyDrive/CS640/final_project/age_dev.csv', sep='\\t', index = False, header = False, columns=['label', 'text']);"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50nutB7GBTFh",
        "outputId": "4afef671-fd55-4b73-bf03-c336560d3849"
      },
      "source": [
        "# init Flair embeddings\n",
        "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
        "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
        "\n",
        "corpus: Corpus = ClassificationCorpus(Path('/content/drive/MyDrive/CS640/final_project'), \n",
        "                            test_file='age_test.csv', \n",
        "                            dev_file='age_dev.csv', \n",
        "                            train_file='age_train.csv')\n",
        "label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "# init BERT base (cases)\n",
        "#optional_embedding = BertEmbeddings('bert-base-cased')\n",
        "# OR init ELMo (original)\n",
        "optional_embedding = ELMoEmbeddings('original')\n",
        "# 3. make a list of word embeddings\n",
        "#word_embeddings = [WordEmbeddings('glove')]\n",
        "word_embeddings = list(filter(None, [\n",
        "    optional_embedding,\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]))\n",
        "\n",
        "# 3. initialize transformer document embeddings (many models are available)\n",
        "#document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n",
        "document_embeddings = DocumentRNNEmbeddings(\n",
        "    word_embeddings,\n",
        "    hidden_size=512,\n",
        "    reproject_words=True,\n",
        "    reproject_words_dimension=256,\n",
        ")\n",
        "\n",
        "# 5. create the text classifier\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
        "\n",
        "# 6. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
        "\n",
        "# 6. start the training\n",
        "trainer.train('/content/drive/MyDrive/CS640/final_project',\n",
        "              learning_rate=0.0003, # use very small learning rate\n",
        "              mini_batch_size=15,\n",
        "              max_epochs=8, # terminate after 5 epochs\n",
        "              )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:35:09,467 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-forward-v0.1.pt not found in cache, downloading to /tmp/tmpy9740ft5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 172513724/172513724 [00:10<00:00, 17144958.73B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:35:20,082 copying /tmp/tmpy9740ft5 to cache at /root/.flair/embeddings/lm-jw300-forward-v0.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:35:20,300 removing temp file /tmp/tmpy9740ft5\n",
            "2021-12-06 04:35:34,178 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-jw300-backward-v0.1.pt not found in cache, downloading to /tmp/tmpz9gw9c2w\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 172513724/172513724 [00:10<00:00, 17009832.84B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:35:44,876 copying /tmp/tmpz9gw9c2w to cache at /root/.flair/embeddings/lm-jw300-backward-v0.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:35:45,101 removing temp file /tmp/tmpz9gw9c2w\n",
            "2021-12-06 04:35:45,789 Reading data from /content/drive/MyDrive/CS640/final_project\n",
            "2021-12-06 04:35:45,790 Train: /content/drive/MyDrive/CS640/final_project/age_train.csv\n",
            "2021-12-06 04:35:45,791 Dev: /content/drive/MyDrive/CS640/final_project/age_dev.csv\n",
            "2021-12-06 04:35:45,792 Test: /content/drive/MyDrive/CS640/final_project/age_test.csv\n",
            "2021-12-06 04:35:46,677 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 65007/65007 [00:30<00:00, 2160.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:17,087 [b'0', b'1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 336/336 [00:00<00:00, 845402.61B/s]\n",
            "100%|██████████| 374434792/374434792 [00:08<00:00, 42914557.77B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:36,371 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpca32qoh7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034624/73034624 [00:04<00:00, 14881636.79B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:41,775 copying /tmp/tmpca32qoh7 to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:41,867 removing temp file /tmp/tmpca32qoh7\n",
            "2021-12-06 04:36:42,573 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmppmhgh6ai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034575/73034575 [00:04<00:00, 14883568.20B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:47,987 copying /tmp/tmppmhgh6ai to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n",
            "2021-12-06 04:36:48,077 removing temp file /tmp/tmppmhgh6ai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:36:48,350 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,352 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): ELMoEmbeddings(model=0-elmo-original-all)\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.05, inplace=False)\n",
            "          (encoder): Embedding(300, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.05, inplace=False)\n",
            "          (encoder): Embedding(300, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=7168, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-12-06 04:36:48,353 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,355 Corpus: \"Corpus: 57784 train + 7223 dev + 7223 test sentences\"\n",
            "2021-12-06 04:36:48,356 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,360 Parameters:\n",
            "2021-12-06 04:36:48,361  - learning_rate: \"0.0003\"\n",
            "2021-12-06 04:36:48,363  - mini_batch_size: \"15\"\n",
            "2021-12-06 04:36:48,367  - patience: \"3\"\n",
            "2021-12-06 04:36:48,369  - anneal_factor: \"0.5\"\n",
            "2021-12-06 04:36:48,371  - max_epochs: \"8\"\n",
            "2021-12-06 04:36:48,372  - shuffle: \"True\"\n",
            "2021-12-06 04:36:48,374  - train_with_dev: \"False\"\n",
            "2021-12-06 04:36:48,376  - batch_growth_annealing: \"False\"\n",
            "2021-12-06 04:36:48,378 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,385 Model training base path: \"/content/drive/MyDrive/CS640/final_project\"\n",
            "2021-12-06 04:36:48,387 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,388 Device: cuda:0\n",
            "2021-12-06 04:36:48,391 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:36:48,392 Embeddings storage mode: cpu\n",
            "2021-12-06 04:36:48,404 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:38:05,075 epoch 1 - iter 385/3853 - loss 0.76375856 - samples/sec: 76.91 - lr: 0.000300\n",
            "2021-12-06 04:39:18,792 epoch 1 - iter 770/3853 - loss 0.75289232 - samples/sec: 79.37 - lr: 0.000300\n",
            "2021-12-06 04:40:32,200 epoch 1 - iter 1155/3853 - loss 0.74461586 - samples/sec: 79.29 - lr: 0.000300\n",
            "2021-12-06 04:41:46,855 epoch 1 - iter 1540/3853 - loss 0.73930610 - samples/sec: 78.40 - lr: 0.000300\n",
            "2021-12-06 04:42:59,030 epoch 1 - iter 1925/3853 - loss 0.73395390 - samples/sec: 81.11 - lr: 0.000300\n",
            "2021-12-06 04:44:13,805 epoch 1 - iter 2310/3853 - loss 0.72835395 - samples/sec: 78.71 - lr: 0.000300\n",
            "2021-12-06 04:45:27,382 epoch 1 - iter 2695/3853 - loss 0.72423480 - samples/sec: 79.01 - lr: 0.000300\n",
            "2021-12-06 04:46:43,170 epoch 1 - iter 3080/3853 - loss 0.72056433 - samples/sec: 77.24 - lr: 0.000300\n",
            "2021-12-06 04:47:58,587 epoch 1 - iter 3465/3853 - loss 0.71766956 - samples/sec: 77.08 - lr: 0.000300\n",
            "2021-12-06 04:49:12,366 epoch 1 - iter 3850/3853 - loss 0.71476949 - samples/sec: 79.42 - lr: 0.000300\n",
            "2021-12-06 04:49:13,074 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 04:49:13,076 EPOCH 1 done: loss 0.7147 - lr 0.0003000\n",
            "2021-12-06 04:50:48,022 DEV : loss 0.6892937421798706 - score 0.5262\n",
            "2021-12-06 04:50:50,637 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-12-06 04:50:52,486 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 04:52:06,881 epoch 2 - iter 385/3853 - loss 0.68684162 - samples/sec: 79.12 - lr: 0.000300\n",
            "2021-12-06 04:53:21,553 epoch 2 - iter 770/3853 - loss 0.68661093 - samples/sec: 77.88 - lr: 0.000300\n",
            "2021-12-06 04:54:35,619 epoch 2 - iter 1155/3853 - loss 0.68592322 - samples/sec: 78.53 - lr: 0.000300\n",
            "2021-12-06 04:55:47,180 epoch 2 - iter 1540/3853 - loss 0.68519988 - samples/sec: 81.23 - lr: 0.000300\n",
            "2021-12-06 04:57:01,279 epoch 2 - iter 1925/3853 - loss 0.68540313 - samples/sec: 78.89 - lr: 0.000300\n",
            "2021-12-06 04:58:13,625 epoch 2 - iter 2310/3853 - loss 0.68548965 - samples/sec: 80.45 - lr: 0.000300\n",
            "2021-12-06 04:59:24,903 epoch 2 - iter 2695/3853 - loss 0.68471511 - samples/sec: 82.16 - lr: 0.000300\n",
            "2021-12-06 05:00:38,676 epoch 2 - iter 3080/3853 - loss 0.68492016 - samples/sec: 79.27 - lr: 0.000300\n",
            "2021-12-06 05:01:50,107 epoch 2 - iter 3465/3853 - loss 0.68470570 - samples/sec: 81.99 - lr: 0.000300\n",
            "2021-12-06 05:03:02,818 epoch 2 - iter 3850/3853 - loss 0.68479895 - samples/sec: 79.89 - lr: 0.000300\n",
            "2021-12-06 05:03:03,237 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 05:03:03,239 EPOCH 2 done: loss 0.6848 - lr 0.0003000\n",
            "2021-12-06 05:04:36,210 DEV : loss 0.6799957752227783 - score 0.5514\n",
            "2021-12-06 05:04:38,795 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-12-06 05:04:40,568 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 05:05:57,742 epoch 3 - iter 385/3853 - loss 0.67703843 - samples/sec: 76.05 - lr: 0.000300\n",
            "2021-12-06 05:07:11,181 epoch 3 - iter 770/3853 - loss 0.67869663 - samples/sec: 79.72 - lr: 0.000300\n",
            "2021-12-06 05:08:24,663 epoch 3 - iter 1155/3853 - loss 0.67916572 - samples/sec: 79.61 - lr: 0.000300\n",
            "2021-12-06 05:09:42,562 epoch 3 - iter 1540/3853 - loss 0.67981955 - samples/sec: 74.73 - lr: 0.000300\n",
            "2021-12-06 05:10:56,480 epoch 3 - iter 1925/3853 - loss 0.67955861 - samples/sec: 79.16 - lr: 0.000300\n",
            "2021-12-06 05:12:11,103 epoch 3 - iter 2310/3853 - loss 0.68030375 - samples/sec: 78.37 - lr: 0.000300\n",
            "2021-12-06 05:13:25,298 epoch 3 - iter 2695/3853 - loss 0.68096814 - samples/sec: 78.96 - lr: 0.000300\n",
            "2021-12-06 05:14:40,411 epoch 3 - iter 3080/3853 - loss 0.68057068 - samples/sec: 77.91 - lr: 0.000300\n",
            "2021-12-06 05:15:56,277 epoch 3 - iter 3465/3853 - loss 0.68027349 - samples/sec: 76.67 - lr: 0.000300\n",
            "2021-12-06 05:17:12,515 epoch 3 - iter 3850/3853 - loss 0.68063359 - samples/sec: 76.36 - lr: 0.000300\n",
            "2021-12-06 05:17:13,094 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 05:17:13,097 EPOCH 3 done: loss 0.6807 - lr 0.0003000\n",
            "2021-12-06 05:18:49,889 DEV : loss 0.6814371943473816 - score 0.5431\n",
            "2021-12-06 05:18:52,585 BAD EPOCHS (no improvement): 1\n",
            "2021-12-06 05:18:52,590 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 05:20:08,614 epoch 4 - iter 385/3853 - loss 0.68141650 - samples/sec: 77.35 - lr: 0.000300\n",
            "2021-12-06 05:21:23,059 epoch 4 - iter 770/3853 - loss 0.68087486 - samples/sec: 78.08 - lr: 0.000300\n",
            "2021-12-06 05:22:36,260 epoch 4 - iter 1155/3853 - loss 0.68020113 - samples/sec: 79.98 - lr: 0.000300\n",
            "2021-12-06 05:23:52,396 epoch 4 - iter 1540/3853 - loss 0.67921426 - samples/sec: 76.88 - lr: 0.000300\n",
            "2021-12-06 05:25:09,753 epoch 4 - iter 1925/3853 - loss 0.67903614 - samples/sec: 75.63 - lr: 0.000300\n",
            "2021-12-06 05:26:25,673 epoch 4 - iter 2310/3853 - loss 0.67928925 - samples/sec: 76.87 - lr: 0.000300\n",
            "2021-12-06 05:27:39,586 epoch 4 - iter 2695/3853 - loss 0.67917958 - samples/sec: 78.63 - lr: 0.000300\n",
            "2021-12-06 05:28:53,331 epoch 4 - iter 3080/3853 - loss 0.67908322 - samples/sec: 79.32 - lr: 0.000300\n",
            "2021-12-06 05:30:06,695 epoch 4 - iter 3465/3853 - loss 0.67896278 - samples/sec: 79.24 - lr: 0.000300\n",
            "2021-12-06 05:31:22,703 epoch 4 - iter 3850/3853 - loss 0.67876336 - samples/sec: 76.99 - lr: 0.000300\n",
            "2021-12-06 05:31:23,332 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 05:31:23,334 EPOCH 4 done: loss 0.6788 - lr 0.0003000\n",
            "2021-12-06 05:32:59,540 DEV : loss 0.6823769211769104 - score 0.5427\n",
            "2021-12-06 05:33:02,225 BAD EPOCHS (no improvement): 2\n",
            "2021-12-06 05:33:02,231 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 05:34:16,469 epoch 5 - iter 385/3853 - loss 0.67498791 - samples/sec: 78.75 - lr: 0.000300\n",
            "2021-12-06 05:35:29,795 epoch 5 - iter 770/3853 - loss 0.67432794 - samples/sec: 79.89 - lr: 0.000300\n",
            "2021-12-06 05:36:43,810 epoch 5 - iter 1155/3853 - loss 0.67408635 - samples/sec: 79.11 - lr: 0.000300\n",
            "2021-12-06 05:37:56,377 epoch 5 - iter 1540/3853 - loss 0.67469366 - samples/sec: 80.64 - lr: 0.000300\n",
            "2021-12-06 05:39:12,027 epoch 5 - iter 1925/3853 - loss 0.67487345 - samples/sec: 76.84 - lr: 0.000300\n",
            "2021-12-06 05:40:27,827 epoch 5 - iter 2310/3853 - loss 0.67555895 - samples/sec: 76.65 - lr: 0.000300\n",
            "2021-12-06 05:41:40,958 epoch 5 - iter 2695/3853 - loss 0.67587922 - samples/sec: 80.05 - lr: 0.000300\n",
            "2021-12-06 05:42:54,160 epoch 5 - iter 3080/3853 - loss 0.67621282 - samples/sec: 79.42 - lr: 0.000300\n",
            "2021-12-06 05:44:09,277 epoch 5 - iter 3465/3853 - loss 0.67630299 - samples/sec: 77.37 - lr: 0.000300\n",
            "2021-12-06 05:45:25,453 epoch 5 - iter 3850/3853 - loss 0.67669204 - samples/sec: 76.33 - lr: 0.000300\n",
            "2021-12-06 05:45:26,004 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 05:45:26,006 EPOCH 5 done: loss 0.6767 - lr 0.0003000\n",
            "2021-12-06 05:47:02,003 DEV : loss 0.6780411005020142 - score 0.5487\n",
            "2021-12-06 05:47:04,731 BAD EPOCHS (no improvement): 3\n",
            "2021-12-06 05:47:04,736 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 05:48:20,287 epoch 6 - iter 385/3853 - loss 0.67251807 - samples/sec: 77.36 - lr: 0.000300\n",
            "2021-12-06 05:49:35,835 epoch 6 - iter 770/3853 - loss 0.67425090 - samples/sec: 76.97 - lr: 0.000300\n",
            "2021-12-06 05:50:51,010 epoch 6 - iter 1155/3853 - loss 0.67528569 - samples/sec: 77.46 - lr: 0.000300\n",
            "2021-12-06 05:52:07,297 epoch 6 - iter 1540/3853 - loss 0.67590104 - samples/sec: 76.61 - lr: 0.000300\n",
            "2021-12-06 05:53:22,636 epoch 6 - iter 1925/3853 - loss 0.67653557 - samples/sec: 77.22 - lr: 0.000300\n",
            "2021-12-06 05:54:37,114 epoch 6 - iter 2310/3853 - loss 0.67629741 - samples/sec: 78.52 - lr: 0.000300\n",
            "2021-12-06 05:55:52,137 epoch 6 - iter 2695/3853 - loss 0.67578680 - samples/sec: 78.37 - lr: 0.000300\n",
            "2021-12-06 05:57:08,669 epoch 6 - iter 3080/3853 - loss 0.67542576 - samples/sec: 76.01 - lr: 0.000300\n",
            "2021-12-06 05:58:23,479 epoch 6 - iter 3465/3853 - loss 0.67568368 - samples/sec: 77.80 - lr: 0.000300\n",
            "2021-12-06 05:59:38,552 epoch 6 - iter 3850/3853 - loss 0.67578301 - samples/sec: 77.94 - lr: 0.000300\n",
            "2021-12-06 05:59:39,155 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 05:59:39,158 EPOCH 6 done: loss 0.6759 - lr 0.0003000\n",
            "2021-12-06 06:01:15,634 DEV : loss 0.6782018542289734 - score 0.5466\n",
            "Epoch     6: reducing learning rate of group 0 to 1.5000e-04.\n",
            "2021-12-06 06:01:18,302 BAD EPOCHS (no improvement): 4\n",
            "2021-12-06 06:01:18,308 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 06:02:33,062 epoch 7 - iter 385/3853 - loss 0.67461090 - samples/sec: 78.61 - lr: 0.000150\n",
            "2021-12-06 06:03:46,300 epoch 7 - iter 770/3853 - loss 0.67051519 - samples/sec: 79.47 - lr: 0.000150\n",
            "2021-12-06 06:05:03,665 epoch 7 - iter 1155/3853 - loss 0.67192788 - samples/sec: 75.67 - lr: 0.000150\n",
            "2021-12-06 06:06:19,399 epoch 7 - iter 1540/3853 - loss 0.67151395 - samples/sec: 76.71 - lr: 0.000150\n",
            "2021-12-06 06:07:33,516 epoch 7 - iter 1925/3853 - loss 0.67088969 - samples/sec: 79.00 - lr: 0.000150\n",
            "2021-12-06 06:08:50,602 epoch 7 - iter 2310/3853 - loss 0.67067999 - samples/sec: 75.89 - lr: 0.000150\n",
            "2021-12-06 06:10:05,140 epoch 7 - iter 2695/3853 - loss 0.67079218 - samples/sec: 78.48 - lr: 0.000150\n",
            "2021-12-06 06:11:18,766 epoch 7 - iter 3080/3853 - loss 0.67041618 - samples/sec: 78.99 - lr: 0.000150\n",
            "2021-12-06 06:12:34,056 epoch 7 - iter 3465/3853 - loss 0.67047730 - samples/sec: 77.66 - lr: 0.000150\n",
            "2021-12-06 06:13:48,505 epoch 7 - iter 3850/3853 - loss 0.67061959 - samples/sec: 79.14 - lr: 0.000150\n",
            "2021-12-06 06:13:49,069 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 06:13:49,072 EPOCH 7 done: loss 0.6707 - lr 0.0001500\n",
            "2021-12-06 06:15:24,975 DEV : loss 0.6775134205818176 - score 0.5517\n",
            "2021-12-06 06:15:27,726 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-12-06 06:15:29,689 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 06:16:45,781 epoch 8 - iter 385/3853 - loss 0.67228910 - samples/sec: 76.79 - lr: 0.000150\n",
            "2021-12-06 06:17:59,821 epoch 8 - iter 770/3853 - loss 0.67072432 - samples/sec: 79.08 - lr: 0.000150\n",
            "2021-12-06 06:19:14,470 epoch 8 - iter 1155/3853 - loss 0.66974651 - samples/sec: 77.96 - lr: 0.000150\n",
            "2021-12-06 06:20:29,314 epoch 8 - iter 1540/3853 - loss 0.67001863 - samples/sec: 78.68 - lr: 0.000150\n",
            "2021-12-06 06:21:44,988 epoch 8 - iter 1925/3853 - loss 0.66949555 - samples/sec: 76.80 - lr: 0.000150\n",
            "2021-12-06 06:23:01,403 epoch 8 - iter 2310/3853 - loss 0.66939780 - samples/sec: 76.15 - lr: 0.000150\n",
            "2021-12-06 06:24:18,561 epoch 8 - iter 2695/3853 - loss 0.66939932 - samples/sec: 75.79 - lr: 0.000150\n",
            "2021-12-06 06:25:31,770 epoch 8 - iter 3080/3853 - loss 0.66900217 - samples/sec: 79.93 - lr: 0.000150\n",
            "2021-12-06 06:26:47,009 epoch 8 - iter 3465/3853 - loss 0.66890237 - samples/sec: 77.66 - lr: 0.000150\n",
            "2021-12-06 06:28:03,291 epoch 8 - iter 3850/3853 - loss 0.66879597 - samples/sec: 77.09 - lr: 0.000150\n",
            "2021-12-06 06:28:03,898 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 06:28:03,900 EPOCH 8 done: loss 0.6688 - lr 0.0001500\n",
            "2021-12-06 06:29:40,676 DEV : loss 0.6791810393333435 - score 0.552\n",
            "2021-12-06 06:29:43,295 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-12-06 06:29:47,086 ----------------------------------------------------------------------------------------------------\n",
            "2021-12-06 06:29:47,088 Testing using best model ...\n",
            "2021-12-06 06:29:47,092 loading file /content/drive/MyDrive/CS640/final_project/best-model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-06 06:31:15,120 \t0.5528\n",
            "2021-12-06 06:31:15,123 \n",
            "Results:\n",
            "- F-score (micro) 0.5528\n",
            "- F-score (macro) 0.5523\n",
            "- Accuracy 0.5528\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5608    0.5751    0.5678      3690\n",
            "           1     0.5441    0.5296    0.5367      3533\n",
            "\n",
            "   micro avg     0.5528    0.5528    0.5528      7223\n",
            "   macro avg     0.5524    0.5523    0.5523      7223\n",
            "weighted avg     0.5526    0.5528    0.5526      7223\n",
            " samples avg     0.5528    0.5528    0.5528      7223\n",
            "\n",
            "2021-12-06 06:31:15,126 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.6892937421798706,\n",
              "  0.6799957752227783,\n",
              "  0.6814371943473816,\n",
              "  0.6823769211769104,\n",
              "  0.6780411005020142,\n",
              "  0.6782018542289734,\n",
              "  0.6775134205818176,\n",
              "  0.6791810393333435],\n",
              " 'dev_score_history': [0.5262,\n",
              "  0.5514,\n",
              "  0.5431,\n",
              "  0.5427,\n",
              "  0.5487,\n",
              "  0.5466,\n",
              "  0.5517,\n",
              "  0.552],\n",
              " 'test_score': 0.5528,\n",
              " 'train_loss_history': [0.7147471720974939,\n",
              "  0.6848269874573744,\n",
              "  0.68072824836427,\n",
              "  0.6788346228462178,\n",
              "  0.6766975680141365,\n",
              "  0.6758834069312902,\n",
              "  0.6706568488912585,\n",
              "  0.6687904705544617]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc4fTw6qBin0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}