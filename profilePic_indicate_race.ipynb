{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from os.path import exists\n",
    "from facenet_pytorch import MTCNN, extract_face\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV files and Prepross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_users = './data/labeled_users.csv'\n",
    "user_demo_profiles_path = './data/User demo profiles.json'\n",
    "\n",
    "df_users = pd.read_csv(labeled_users)\n",
    "df_profiles = pd.read_json(user_demo_profiles_path, orient='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = df_users.drop(['is_female','year_born'],axis = 1)\n",
    "df_users = df_users.rename(columns={\"user_id\":\"id\",\"race\":\"race\"})\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profiles = df_profiles.drop(['name','screen_name','description','lang'],axis = 1)\n",
    "df_profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_users.join(df_profiles.set_index('id'), on='id')\n",
    "data = data.dropna()\n",
    "data['img_path'] = './data/' + data['img_path']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "to_drop = []\n",
    "for i, row in enumerate(data.iterrows()):\n",
    "    index, row = row\n",
    "    path = row['img_path']\n",
    "    if not exists(path):\n",
    "        to_drop.append(index)\n",
    "data = data.drop(to_drop)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little test\n",
    "test_path = './data/profile pics/60152.jpeg'#data['img_path'][0]\n",
    "img = Image.open(test_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detector\n",
    "mtcnn = MTCNN(keep_all=True,select_largest=True)\n",
    "boxes, probs, points = mtcnn.detect(img, landmarks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw boxes and save faces\n",
    "extract = extract_face(img, boxes[0], save_path='detected_face_{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_faces(input):\n",
    "    return Image.open(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['img'] = data['img_path'].apply(get_all_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, probs = mtcnn.detect(data['img'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['boxes'] = boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extract(para):\n",
    "    image, boxes = para[0], para[1]\n",
    "    if boxes is None:\n",
    "        return pd.NA\n",
    "    else:\n",
    "        return extract_face(image, boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tensor'] = data[['img','boxes']].apply(get_extract, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['img_path','img','boxes'])\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('./Dataset1_id_Race_FaceTensor.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f75978233c496711d8b6fbaac206609b5c6c1b124626415f694fad520d3d3bd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('cs640': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
