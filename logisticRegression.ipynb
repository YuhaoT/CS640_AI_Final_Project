{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0b50b0-1661-42c7-ae09-19b67e2b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24d13ff-f08f-4dec-934c-a08249711198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>all_tweets</th>\n",
       "      <th>is_female</th>\n",
       "      <th>year_born</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12488</td>\n",
       "      <td>ykar futuristic sans serif font who can contac...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>719703</td>\n",
       "      <td>other words good news about the vaccine safety...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>749003</td>\n",
       "      <td>would fair call lil nas the first successful o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>822540</td>\n",
       "      <td>bonk  nice mcboy oos getting real tired games...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>865071</td>\n",
       "      <td>how about pizza dipped water day quarantine in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>3270</td>\n",
       "      <td>3196361888</td>\n",
       "      <td>back someone called hungry who back watch sock...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>3272</td>\n",
       "      <td>3352812676</td>\n",
       "      <td>women guide burn fat and build muscle the holy...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>3273</td>\n",
       "      <td>3924536853</td>\n",
       "      <td>even though school cancelled and grades don ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>3274</td>\n",
       "      <td>4281628276</td>\n",
       "      <td>and what are you drunk hillary supporter women...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>3275</td>\n",
       "      <td>4467793452</td>\n",
       "      <td>married    husbands ios android brasspistol ev...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     user_id  \\\n",
       "0              0       12488   \n",
       "1              1      719703   \n",
       "2              2      749003   \n",
       "3              3      822540   \n",
       "4              4      865071   \n",
       "...          ...         ...   \n",
       "3266        3270  3196361888   \n",
       "3267        3272  3352812676   \n",
       "3268        3273  3924536853   \n",
       "3269        3274  4281628276   \n",
       "3270        3275  4467793452   \n",
       "\n",
       "                                             all_tweets  is_female  year_born  \\\n",
       "0     ykar futuristic sans serif font who can contac...        0.0     1980.0   \n",
       "1     other words good news about the vaccine safety...        0.0     1985.0   \n",
       "2     would fair call lil nas the first successful o...        0.0     1982.0   \n",
       "3      bonk  nice mcboy oos getting real tired games...        0.0     1979.0   \n",
       "4     how about pizza dipped water day quarantine in...        0.0     1995.0   \n",
       "...                                                 ...        ...        ...   \n",
       "3266  back someone called hungry who back watch sock...        1.0     1995.0   \n",
       "3267  women guide burn fat and build muscle the holy...        1.0     1973.0   \n",
       "3268  even though school cancelled and grades don ma...        1.0     1993.0   \n",
       "3269  and what are you drunk hillary supporter women...        0.0     1987.0   \n",
       "3270  married    husbands ios android brasspistol ev...        1.0     1996.0   \n",
       "\n",
       "      race  \n",
       "0      4.0  \n",
       "1      4.0  \n",
       "2      5.0  \n",
       "3      4.0  \n",
       "4      4.0  \n",
       "...    ...  \n",
       "3266   1.0  \n",
       "3267   4.0  \n",
       "3268   4.0  \n",
       "3269   4.0  \n",
       "3270   NaN  \n",
       "\n",
       "[3271 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/preprocessed_tweets_with_race&age.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385efcf6-2c57-4f55-9425-875b63384c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stem \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4153b70-eb4c-414d-a85a-57a48657a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stem_wrds = []\n",
    "for txt in df['all_tweets']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)\n",
    "    all_stem_wrds.append(str1)\n",
    "\n",
    "df['stemmed_tweets'] = all_stem_wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e8f5d8-cb2a-44c1-92d9-f113909f32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop NaN\n",
    "df = df.dropna(subset=['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d564c753-41ba-49d8-b20e-234d0b95e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3241, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features = 5000)\n",
    "\n",
    "X = vectorizer.fit_transform(df['stemmed_tweets'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a563e65d-1ea1-428f-8ce5-2b5998d45490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2534\n",
       "1.0     299\n",
       "2.0     186\n",
       "5.0     120\n",
       "3.0     102\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ebc0d-94ba-4718-8d08-7fe76154c9c5",
   "metadata": {},
   "source": [
    "4 is white, 1 is black, and merge all other race to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414f8c42-875b-44bf-bc13-ccef79b5ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0    2534\n",
      "0.0     408\n",
      "1.0     299\n",
      "Name: race, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, 'race'] = np.where(\n",
    "   (df['race'] != 4) & (df['race'] != 1) , 0.0, df['race']\n",
    "   )\n",
    "\n",
    "print(df['race'].value_counts())\n",
    "y = df['race']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63acde-0f55-4936-91a9-06694e29fce0",
   "metadata": {},
   "source": [
    "### logistic regression + TFIDF vectorizor & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21a17cb-33a9-4043-bad4-c9098794ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec9a0bd-a00b-4e65-8742-c4905d0ed85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    print(confusion_matrix(y_true, y_pred, labels = [0,1,4]))\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24252b4a-d783-4a6f-91dd-aa4d73b08741",
   "metadata": {},
   "source": [
    "#### classification report for race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593b2b57-e426-4340-ab9c-252c5c35f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.12      0.16        82\n",
      "         1.0       0.45      0.28      0.35        60\n",
      "         4.0       0.82      0.92      0.87       507\n",
      "\n",
      "    accuracy                           0.76       649\n",
      "   macro avg       0.50      0.44      0.46       649\n",
      "weighted avg       0.71      0.76      0.73       649\n",
      "\n",
      "[[ 10   8  64]\n",
      " [  6  17  37]\n",
      " [ 28  13 466]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.16      0.19        82\n",
      "         1.0       0.38      0.29      0.33        59\n",
      "         4.0       0.83      0.89      0.86       507\n",
      "\n",
      "    accuracy                           0.75       648\n",
      "   macro avg       0.48      0.45      0.46       648\n",
      "weighted avg       0.71      0.75      0.73       648\n",
      "\n",
      "[[ 13   8  61]\n",
      " [  8  17  34]\n",
      " [ 34  20 453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.15      0.07      0.10        81\n",
      "         1.0       0.42      0.33      0.37        60\n",
      "         4.0       0.82      0.91      0.86       507\n",
      "\n",
      "    accuracy                           0.75       648\n",
      "   macro avg       0.46      0.44      0.44       648\n",
      "weighted avg       0.70      0.75      0.72       648\n",
      "\n",
      "[[  6   7  68]\n",
      " [  7  20  33]\n",
      " [ 27  21 459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.15      0.20        81\n",
      "         1.0       0.44      0.37      0.40        60\n",
      "         4.0       0.83      0.91      0.87       507\n",
      "\n",
      "    accuracy                           0.76       648\n",
      "   macro avg       0.52      0.47      0.49       648\n",
      "weighted avg       0.72      0.76      0.74       648\n",
      "\n",
      "[[ 12   3  66]\n",
      " [  8  22  30]\n",
      " [ 22  25 460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.12      0.16        82\n",
      "         1.0       0.39      0.22      0.28        60\n",
      "         4.0       0.82      0.92      0.87       506\n",
      "\n",
      "    accuracy                           0.76       648\n",
      "   macro avg       0.48      0.42      0.44       648\n",
      "weighted avg       0.71      0.76      0.72       648\n",
      "\n",
      "[[ 10   8  64]\n",
      " [  8  13  39]\n",
      " [ 26  12 468]]\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(with_mean=False), LogisticRegression(max_iter=500))\n",
    "scores = cross_val_score(clf, X, y, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54151f-6a8a-4b1d-bc57-ad43e7d9b06a",
   "metadata": {},
   "source": [
    "#### classification report for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a37db7-dd98-4ad5-99c4-d63054fb7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = pd.read_csv('./data/preprocessed_tweets_with_for_age_pred.csv',  lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc4b3be8-7588-4b3c-a146-afe2e6036c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stem_wrds = []\n",
    "for txt in df_age['all_tweets']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)\n",
    "    all_stem_wrds.append(str1)\n",
    "\n",
    "df_age['stemmed_tweets'] = all_stem_wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f75d6d-70e5-4f2d-92b2-8d9159b14edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    718\n",
       "0    427\n",
       "Name: human.labeled.age, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_age = df_age['human.labeled.age']\n",
    "df_age['human.labeled.age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac73793-2a95-490e-bfed-e7460bea985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1145, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_age = vectorizer.fit_transform(df_age['stemmed_tweets'])\n",
    "print(X_age.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7a29ca-7b3d-449f-91d9-abdf56df5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55        85\n",
      "           1       0.73      0.81      0.77       144\n",
      "\n",
      "    accuracy                           0.69       229\n",
      "   macro avg       0.67      0.65      0.66       229\n",
      "weighted avg       0.69      0.69      0.69       229\n",
      "\n",
      "[[ 42  43   0]\n",
      " [ 27 117   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.40      0.48        85\n",
      "           1       0.70      0.84      0.77       144\n",
      "\n",
      "    accuracy                           0.68       229\n",
      "   macro avg       0.65      0.62      0.62       229\n",
      "weighted avg       0.66      0.68      0.66       229\n",
      "\n",
      "[[ 34  51   0]\n",
      " [ 23 121   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.41      0.51        85\n",
      "           1       0.72      0.88      0.79       144\n",
      "\n",
      "    accuracy                           0.70       229\n",
      "   macro avg       0.69      0.64      0.65       229\n",
      "weighted avg       0.70      0.70      0.68       229\n",
      "\n",
      "[[ 35  50   0]\n",
      " [ 18 126   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.41      0.45        86\n",
      "           1       0.68      0.75      0.71       143\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.59      0.58      0.58       229\n",
      "weighted avg       0.61      0.62      0.61       229\n",
      "\n",
      "[[ 35  51   0]\n",
      " [ 36 107   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.40      0.44        86\n",
      "           1       0.68      0.77      0.72       143\n",
      "\n",
      "    accuracy                           0.63       229\n",
      "   macro avg       0.59      0.58      0.58       229\n",
      "weighted avg       0.61      0.63      0.62       229\n",
      "\n",
      "[[ 34  52   0]\n",
      " [ 33 110   0]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_age, y_age, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c0eac-c967-434b-a560-3e42dda932b7",
   "metadata": {},
   "source": [
    "### word2vec + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad63e92-b9dc-4ef5-87c0-14dab175c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e418409-3f51-4e2b-8e8d-e3fe1b7c6cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=df['all_tweets'], vector_size=500, min_count=5)    \n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")\n",
    "\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
    "# print(wv['ま'])\n",
    "def document_vector(doc, wv = wv):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word for word in doc if word in wv.key_to_index]\n",
    "    return np.mean(wv[doc], axis=0)\n",
    "\n",
    "df.loc[:, 'doc_vector']  = df.all_tweets.apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a267fbc0-234e-4567-bd55-dea2e2c2e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['doc_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c28ae4-b099-424c-952b-99099a484319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02        82\n",
      "         1.0       0.00      0.00      0.00        60\n",
      "         4.0       0.78      1.00      0.88       507\n",
      "\n",
      "    accuracy                           0.78       649\n",
      "   macro avg       0.59      0.34      0.30       649\n",
      "weighted avg       0.74      0.78      0.69       649\n",
      "\n",
      "[[  1   0  81]\n",
      " [  0   0  60]\n",
      " [  0   0 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.01      0.02        82\n",
      "         1.0       0.00      0.00      0.00        59\n",
      "         4.0       0.78      0.99      0.87       507\n",
      "\n",
      "    accuracy                           0.77       648\n",
      "   macro avg       0.32      0.33      0.30       648\n",
      "weighted avg       0.63      0.77      0.69       648\n",
      "\n",
      "[[  1   0  81]\n",
      " [  1   0  58]\n",
      " [  4   3 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.01      0.02        81\n",
      "         1.0       0.12      0.02      0.03        60\n",
      "         4.0       0.78      0.98      0.87       507\n",
      "\n",
      "    accuracy                           0.77       648\n",
      "   macro avg       0.37      0.34      0.31       648\n",
      "weighted avg       0.65      0.77      0.69       648\n",
      "\n",
      "[[  1   1  79]\n",
      " [  1   1  58]\n",
      " [  3   6 498]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        81\n",
      "         1.0       0.17      0.02      0.03        60\n",
      "         4.0       0.78      0.99      0.88       507\n",
      "\n",
      "    accuracy                           0.78       648\n",
      "   macro avg       0.32      0.34      0.30       648\n",
      "weighted avg       0.63      0.78      0.69       648\n",
      "\n",
      "[[  0   2  79]\n",
      " [  0   1  59]\n",
      " [  2   3 502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.01      0.02        82\n",
      "         1.0       0.00      0.00      0.00        60\n",
      "         4.0       0.78      1.00      0.88       506\n",
      "\n",
      "    accuracy                           0.78       648\n",
      "   macro avg       0.43      0.34      0.30       648\n",
      "weighted avg       0.67      0.78      0.69       648\n",
      "\n",
      "[[  1   0  81]\n",
      " [  0   0  60]\n",
      " [  1   0 505]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(with_mean=False), LogisticRegression(max_iter=5000))\n",
    "scores = cross_val_score(clf, X, y, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219a752-a165-43b5-89c7-3b05e0874893",
   "metadata": {},
   "source": [
    "#### Age prediction with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29bafa2-ff68-4fc3-ac46-c47621ab92e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=df_age['all_tweets'], vector_size=500, min_count=5)    \n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec_age.wordvectors\")\n",
    "\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"word2vec_age.wordvectors\", mmap='r')\n",
    "def document_vector(doc, wv = wv):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word for word in doc if word in wv.key_to_index]\n",
    "    return np.mean(wv[doc], axis=0)\n",
    "df_age.loc[:, 'doc_vector']  = df_age.all_tweets.apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd1b87e9-6934-4981-b09b-3398a5d527f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_age = list(df_age['doc_vector'])\n",
    "len(X_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a16f32f0-591f-40a6-8318-9d618ebfeb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_age['all_tweets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b1c450-034e-479f-bc40-9a7118917cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.20      0.30        85\n",
      "           1       0.66      0.92      0.77       144\n",
      "\n",
      "    accuracy                           0.65       229\n",
      "   macro avg       0.62      0.56      0.53       229\n",
      "weighted avg       0.63      0.65      0.59       229\n",
      "\n",
      "[[ 17  68   0]\n",
      " [ 12 132   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.15      0.24        85\n",
      "           1       0.65      0.93      0.77       144\n",
      "\n",
      "    accuracy                           0.64       229\n",
      "   macro avg       0.61      0.54      0.50       229\n",
      "weighted avg       0.62      0.64      0.57       229\n",
      "\n",
      "[[ 13  72   0]\n",
      " [ 10 134   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.24      0.32        85\n",
      "           1       0.66      0.86      0.74       144\n",
      "\n",
      "    accuracy                           0.63       229\n",
      "   macro avg       0.58      0.55      0.53       229\n",
      "weighted avg       0.60      0.63      0.59       229\n",
      "\n",
      "[[ 20  65   0]\n",
      " [ 20 124   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.10      0.17        86\n",
      "           1       0.63      0.92      0.75       143\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.54      0.51      0.46       229\n",
      "weighted avg       0.56      0.62      0.53       229\n",
      "\n",
      "[[  9  77   0]\n",
      " [ 11 132   0]\n",
      " [  0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.29      0.36        86\n",
      "           1       0.66      0.81      0.72       143\n",
      "\n",
      "    accuracy                           0.62       229\n",
      "   macro avg       0.57      0.55      0.54       229\n",
      "weighted avg       0.59      0.62      0.59       229\n",
      "\n",
      "[[ 25  61   0]\n",
      " [ 27 116   0]\n",
      " [  0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_age, y_age, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
