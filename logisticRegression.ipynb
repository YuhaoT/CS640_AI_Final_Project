{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0b50b0-1661-42c7-ae09-19b67e2b4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24d13ff-f08f-4dec-934c-a08249711198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ykar futuristic sans serif font</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other words good news about the vaccine safety...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>719703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how about pizza dipped water</td>\n",
       "      <td>4.0</td>\n",
       "      <td>865071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hire better programmers your website dumpster ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>988211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>walking home from the adella wonders the raven...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327593</th>\n",
       "      <td>username danisonbottom wattpad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3178803853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327594</th>\n",
       "      <td>like going summer shopping today</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3196361888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327596</th>\n",
       "      <td>what the best for guide nutritional needs heal...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3352812676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327597</th>\n",
       "      <td>freakin panthers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3924536853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327598</th>\n",
       "      <td>raising money for help feed the homeless click...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4281628276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276037 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label     user_id\n",
       "0                         ykar futuristic sans serif font    4.0       12488\n",
       "1       other words good news about the vaccine safety...    4.0      719703\n",
       "4                            how about pizza dipped water    4.0      865071\n",
       "5       hire better programmers your website dumpster ...    4.0      988211\n",
       "6       walking home from the adella wonders the raven...    4.0     1025311\n",
       "...                                                   ...    ...         ...\n",
       "327593                     username danisonbottom wattpad    2.0  3178803853\n",
       "327594                   like going summer shopping today    1.0  3196361888\n",
       "327596  what the best for guide nutritional needs heal...    4.0  3352812676\n",
       "327597                                   freakin panthers    4.0  3924536853\n",
       "327598  raising money for help feed the homeless click...    4.0  4281628276\n",
       "\n",
       "[276037 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df = pd.read_csv('./data/preprocessed_race_tweets.csv', index_col = 0)\n",
    "race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e8f5d8-cb2a-44c1-92d9-f113909f32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop NaN\n",
    "race_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a563e65d-1ea1-428f-8ce5-2b5998d45490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    224287\n",
       "1.0     26269\n",
       "2.0     16292\n",
       "3.0      9189\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9973fe5-dc2e-4e17-a01c-7b1dc9933737",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b233c25d-8260-4a14-8c7b-1b980d4e6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "all_stem_wrds = []\n",
    "for txt in df['text']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)\n",
    "    all_stem_wrds.append(str1)\n",
    "\n",
    "df['text'] = all_stem_wrds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ebc0d-94ba-4718-8d08-7fe76154c9c5",
   "metadata": {},
   "source": [
    "### Sampling from each label\n",
    "1: Black, 2: Latino/Hspanic, 3: Asian, 4: White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9844a6c7-3ec0-46e8-b7f9-81d823a7f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.DataFrame({'label':[1, 2, 3, 4],\n",
    "                     'nostoextract':[9000, 9000, 9000, 9000], })\n",
    "\n",
    "def bootstrap(data, freq):\n",
    "    freq = freq.set_index('label')\n",
    "\n",
    "    # This function will be applied on each group of instances of the same\n",
    "    # class in `data`.\n",
    "    def sampleClass(classgroup):\n",
    "        cls = classgroup['label'].iloc[0]\n",
    "        nDesired = freq.nostoextract[cls]\n",
    "        nRows = len(classgroup)\n",
    "\n",
    "        nSamples = min(nRows, nDesired)\n",
    "        return classgroup.sample(nSamples)\n",
    "\n",
    "    samples = data.groupby('label').apply(sampleClass)\n",
    "\n",
    "    # If you want a new index with ascending values\n",
    "    # samples.index = range(len(samples))\n",
    "\n",
    "    # If you want an index which is equal to the row in `data` where the sample\n",
    "    # came from\n",
    "    samples.index = samples.index.get_level_values(1)\n",
    "\n",
    "    # If you don't change it then you'll have a multiindex with level 0\n",
    "    # being the class and level 1 being the row in `data` where\n",
    "    # the sample came from.\n",
    "\n",
    "    return samples\n",
    "\n",
    "sampled_race_df = bootstrap(race_df,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385efcf6-2c57-4f55-9425-875b63384c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stem \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4153b70-eb4c-414d-a85a-57a48657a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_list = []\n",
    "for txt in sampled_race_df['text']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    \n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)  \n",
    "    stem_list.append(str1)\n",
    "\n",
    "sampled_race_df['text'] = stem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5c36c7-a532-4460-85fc-e86d9a7f0721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features = 5000)\n",
    "\n",
    "X = vectorizer.fit_transform(sampled_race_df['text'])\n",
    "print(X.shape)\n",
    "y = sampled_race_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63acde-0f55-4936-91a9-06694e29fce0",
   "metadata": {},
   "source": [
    "### logistic regression + TFIDF vectorizor & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21a17cb-33a9-4043-bad4-c9098794ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec9a0bd-a00b-4e65-8742-c4905d0ed85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    # print(confusion_matrix(y_true, y_pred, labels = [1,2,3,4], normalize='true'))\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24252b4a-d783-4a6f-91dd-aa4d73b08741",
   "metadata": {},
   "source": [
    "#### classification report for race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593b2b57-e426-4340-ab9c-252c5c35f2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.38      0.38      0.38      1800\n",
      "         2.0       0.33      0.31      0.32      1800\n",
      "         3.0       0.37      0.42      0.39      1800\n",
      "         4.0       0.34      0.32      0.33      1800\n",
      "\n",
      "    accuracy                           0.36      7200\n",
      "   macro avg       0.36      0.36      0.36      7200\n",
      "weighted avg       0.36      0.36      0.36      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.38      0.37      0.38      1800\n",
      "         2.0       0.34      0.33      0.34      1800\n",
      "         3.0       0.37      0.41      0.39      1800\n",
      "         4.0       0.33      0.31      0.32      1800\n",
      "\n",
      "    accuracy                           0.36      7200\n",
      "   macro avg       0.36      0.36      0.35      7200\n",
      "weighted avg       0.36      0.36      0.35      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.37      0.38      1800\n",
      "         2.0       0.35      0.35      0.35      1800\n",
      "         3.0       0.37      0.41      0.39      1800\n",
      "         4.0       0.33      0.31      0.32      1800\n",
      "\n",
      "    accuracy                           0.36      7200\n",
      "   macro avg       0.36      0.36      0.36      7200\n",
      "weighted avg       0.36      0.36      0.36      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.39      0.39      1800\n",
      "         2.0       0.37      0.34      0.36      1800\n",
      "         3.0       0.38      0.43      0.40      1800\n",
      "         4.0       0.33      0.31      0.32      1800\n",
      "\n",
      "    accuracy                           0.37      7200\n",
      "   macro avg       0.37      0.37      0.37      7200\n",
      "weighted avg       0.37      0.37      0.37      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      0.40      0.40      1800\n",
      "         2.0       0.35      0.34      0.34      1800\n",
      "         3.0       0.38      0.42      0.40      1800\n",
      "         4.0       0.33      0.31      0.32      1800\n",
      "\n",
      "    accuracy                           0.36      7200\n",
      "   macro avg       0.36      0.36      0.36      7200\n",
      "weighted avg       0.36      0.36      0.36      7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(with_mean=False), LogisticRegression(max_iter=500))\n",
    "scores = cross_val_score(clf, X, y, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54151f-6a8a-4b1d-bc57-ad43e7d9b06a",
   "metadata": {},
   "source": [
    "#### classification report for age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a37db7-dd98-4ad5-99c4-d63054fb7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = pd.read_csv('./data/preprocessed_tweets_with_for_age_pred.csv',  lineterminator='\\n')\n",
    "## drop NaN\n",
    "age_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7caf64-cff9-4f92-b7fe-316d72841696",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_list = []\n",
    "for txt in sampled_age_df['text']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    \n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)  \n",
    "    stem_list.append(str1)\n",
    "\n",
    "sampled_age_df['text'] = stem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e38903-838e-47ef-9e14-1caa858b4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample from age_df\n",
    "freq = pd.DataFrame({'label':[0, 1],\n",
    "                     'nostoextract':[36115, 36115], })\n",
    "sampled_age_df = bootstrap(age_df,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc4b3be8-7588-4b3c-a146-afe2e6036c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stem_wrds = []\n",
    "for txt in sampled_age_df['text']:\n",
    "    wrds = txt.split()\n",
    "    stem_wrds = []\n",
    "    for i in wrds:\n",
    "        stem_wrds.append(stemmer.stem(i))\n",
    "    \n",
    "    str1 = ' '.join(stem_wrds)\n",
    "    all_stem_wrds.append(str1)\n",
    "\n",
    "sampled_age_df['text'] = all_stem_wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f75d6d-70e5-4f2d-92b2-8d9159b14edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36115\n",
       "1    36115\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_age_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac73793-2a95-490e-bfed-e7460bea985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72230, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_age = vectorizer.fit_transform(sampled_age_df['text'])\n",
    "print(X_age.shape)\n",
    "y_age = sampled_age_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7a29ca-7b3d-449f-91d9-abdf56df5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      7223\n",
      "           1       0.57      0.52      0.54      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      7223\n",
      "           1       0.57      0.50      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      7223\n",
      "           1       0.57      0.51      0.54      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.58      7223\n",
      "           1       0.56      0.51      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      7223\n",
      "           1       0.57      0.50      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_age, y_age, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c0eac-c967-434b-a560-3e42dda932b7",
   "metadata": {},
   "source": [
    "### word2vec + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad63e92-b9dc-4ef5-87c0-14dab175c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2e389-53e1-4c2b-a4be-01fe1dd77379",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### race prediction with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f92db80-c0f4-4cbf-abd3-c9d9ec7f054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "common_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d9bf6c-1366-4347-a5da-4c93675900e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you',\n",
       "  'play',\n",
       "  'volleybal',\n",
       "  'too',\n",
       "  'you',\n",
       "  'are',\n",
       "  'more',\n",
       "  'than',\n",
       "  'tripl',\n",
       "  'threat',\n",
       "  'your',\n",
       "  'the',\n",
       "  'next',\n",
       "  'level',\n",
       "  'woman'],\n",
       " ['ye', 'and', 'great', 'see', 'real', 'life', 'candyland'],\n",
       " ['everybodi',\n",
       "  'wanna',\n",
       "  'leav',\n",
       "  'facebook',\n",
       "  'for',\n",
       "  'twitter',\n",
       "  'nah',\n",
       "  'keep',\n",
       "  'all',\n",
       "  'ass',\n",
       "  'over',\n",
       "  'there']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd_ls = []\n",
    "for s in sampled_race_df['text'].to_list():\n",
    "    wrd_ls.append(s.split())\n",
    "    \n",
    "wrd_ls[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42a1077c-d4a8-487c-a978-aae52a530595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=wrd_ls, vector_size=500)    \n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d9edd-85ff-49a2-bc37-cff2d59e1566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
    "\n",
    "print(wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39b472d2-3753-4d22-82b8-d8ada78afdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv[\"<UNK>\"] = np.random.rand(500) # 500 is the vectors length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42d95c8a-fcd5-4c21-b278-8c7506e3be39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def document_vector(doc, wv = wv):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word if word in wv.key_to_index else \"<UNK>\" for word in doc ]\n",
    "    return np.mean(wv[doc], axis=0)\n",
    "\n",
    "sampled_race_df.loc[:, 'doc_vector']  = [document_vector(s) for s in wrd_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6a09e-e6af-47be-a21e-6e9335bede38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a267fbc0-234e-4567-bd55-dea2e2c2e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sampled_race_df['doc_vector'].to_list()\n",
    "y = sampled_race_df['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2c28ae4-b099-424c-952b-99099a484319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.34      0.34      0.34      1800\n",
      "         2.0       0.30      0.26      0.27      1800\n",
      "         3.0       0.32      0.33      0.32      1800\n",
      "         4.0       0.30      0.33      0.31      1800\n",
      "\n",
      "    accuracy                           0.31      7200\n",
      "   macro avg       0.31      0.31      0.31      7200\n",
      "weighted avg       0.31      0.31      0.31      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.33      0.35      0.34      1800\n",
      "         2.0       0.32      0.24      0.28      1800\n",
      "         3.0       0.33      0.35      0.34      1800\n",
      "         4.0       0.29      0.33      0.31      1800\n",
      "\n",
      "    accuracy                           0.32      7200\n",
      "   macro avg       0.32      0.32      0.32      7200\n",
      "weighted avg       0.32      0.32      0.32      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.33      0.37      0.35      1800\n",
      "         2.0       0.32      0.25      0.28      1800\n",
      "         3.0       0.34      0.35      0.34      1800\n",
      "         4.0       0.31      0.33      0.32      1800\n",
      "\n",
      "    accuracy                           0.33      7200\n",
      "   macro avg       0.33      0.33      0.32      7200\n",
      "weighted avg       0.33      0.33      0.32      7200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.35      0.36      0.35      1800\n",
      "         2.0       0.32      0.27      0.29      1800\n",
      "         3.0       0.32      0.31      0.32      1800\n",
      "         4.0       0.30      0.35      0.33      1800\n",
      "\n",
      "    accuracy                           0.32      7200\n",
      "   macro avg       0.32      0.32      0.32      7200\n",
      "weighted avg       0.32      0.32      0.32      7200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.35      0.38      0.36      1800\n",
      "         2.0       0.31      0.27      0.29      1800\n",
      "         3.0       0.32      0.33      0.32      1800\n",
      "         4.0       0.31      0.33      0.32      1800\n",
      "\n",
      "    accuracy                           0.32      7200\n",
      "   macro avg       0.32      0.32      0.32      7200\n",
      "weighted avg       0.32      0.32      0.32      7200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/yuhao/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(with_mean=False), LogisticRegression(max_iter=2000, solver='newton-cg'))\n",
    "scores = cross_val_score(clf, X, y, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219a752-a165-43b5-89c7-3b05e0874893",
   "metadata": {},
   "source": [
    "#### Age prediction with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b29bafa2-ff68-4fc3-ac46-c47621ab92e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sampled_age_df['text'], vector_size=500)    \n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec_age.wordvectors\")\n",
    "\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(\"word2vec_age.wordvectors\", mmap='r')\n",
    "wv[\"<UNK>\"] = np.random.rand(500) # 500 is the vectors length\n",
    "sampled_age_df.loc[:, 'doc_vector']  = sampled_age_df.text.apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd1b87e9-6934-4981-b09b-3398a5d527f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_age = list(sampled_age_df['doc_vector'])\n",
    "len(X_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23b1c450-034e-479f-bc40-9a7118917cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      7223\n",
      "           1       0.57      0.52      0.54      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      7223\n",
      "           1       0.57      0.50      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      7223\n",
      "           1       0.57      0.51      0.54      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.58      7223\n",
      "           1       0.56      0.51      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      7223\n",
      "           1       0.57      0.50      0.53      7223\n",
      "\n",
      "    accuracy                           0.56     14446\n",
      "   macro avg       0.56      0.56      0.56     14446\n",
      "weighted avg       0.56      0.56      0.56     14446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_age, y_age, cv=5, \\\n",
    "               scoring=make_scorer(classification_report_with_accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6871d-6ecc-4b47-9ec0-cd3df9e04fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
