{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f26cdc8-8ebd-42da-88cf-cb14d3c163be",
   "metadata": {
    "id": "4f26cdc8-8ebd-42da-88cf-cb14d3c163be"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6exlB6bQk5hX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6exlB6bQk5hX",
    "outputId": "731e3506-3372-414e-8149-f1c91ae2dd87"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fa55bf9-71b6-4261-a889-8403efa23c33",
   "metadata": {
    "id": "8fa55bf9-71b6-4261-a889-8403efa23c33",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# race_df = pd.read_csv('/content/drive/MyDrive/CS640/final_project/preprocessed_race_tweets.csv')\n",
    "race_df = pd.read_csv('./data/preprocessed_race_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d9b990a-9768-4fb8-b20d-da8b13ee783c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d9b990a-9768-4fb8-b20d-da8b13ee783c",
    "outputId": "56895fbf-7e58-43c2-a851-713fec0b85e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_id', '0', '1', '2', '3', '4', '5', '6', '7',\n",
       "       ...\n",
       "       '93', '94', '95', '96', '97', '98', '99', 'is_female', 'year_born',\n",
       "       'race'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ff477b6-eca0-4966-b296-982d7428368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2539\n",
       "1.0     299\n",
       "2.0     186\n",
       "5.0     120\n",
       "3.0     102\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99975aa9-272e-49ee-b1e6-00b0cebced29",
   "metadata": {
    "id": "99975aa9-272e-49ee-b1e6-00b0cebced29"
   },
   "source": [
    "##### Label formatting for Race data:\n",
    "4 is white, 1 is black, and merge all other race to 0, then change 4 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aef99ff7-04c6-4f25-921c-783f3eb34e84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aef99ff7-04c6-4f25-921c-783f3eb34e84",
    "outputId": "c0e7a88a-53ac-4710-b590-7e1b7bb94e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    224287\n",
      "0.0     38563\n",
      "1.0     26269\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "race_df.loc[:, 'label'] = np.where(\n",
    "   (race_df['label'] != 4) & (race_df['label'] != 1) , 0.0, race_df['label']\n",
    "   )\n",
    "\n",
    "race_df.loc[:, 'label'] = np.where((race_df['label'] == 4.0), 2.0, race_df['label'])  \n",
    "    \n",
    "print(race_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a214c-5d0d-4b1f-9099-8862d3284ee9",
   "metadata": {
    "id": "cc4a214c-5d0d-4b1f-9099-8862d3284ee9"
   },
   "source": [
    "sample 10000 data from each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959db6ce-3fc6-43d6-be94-82d97b4cb19a",
   "metadata": {
    "id": "959db6ce-3fc6-43d6-be94-82d97b4cb19a"
   },
   "outputs": [],
   "source": [
    "freq = pd.DataFrame({'label':[0, 1, 2],\n",
    "                     'nostoextract':[10000, 15000, 25000], })\n",
    "\n",
    "def bootstrap(data, freq):\n",
    "    freq = freq.set_index('label')\n",
    "\n",
    "    # This function will be applied on each group of instances of the same\n",
    "    # class in `data`.\n",
    "    def sampleClass(classgroup):\n",
    "        cls = classgroup['label'].iloc[0]\n",
    "        nDesired = freq.nostoextract[cls]\n",
    "        nRows = len(classgroup)\n",
    "\n",
    "        nSamples = min(nRows, nDesired)\n",
    "        return classgroup.sample(nSamples)\n",
    "\n",
    "    samples = data.groupby('label').apply(sampleClass)\n",
    "\n",
    "    # If you want a new index with ascending values\n",
    "    # samples.index = range(len(samples))\n",
    "\n",
    "    # If you want an index which is equal to the row in `data` where the sample\n",
    "    # came from\n",
    "    samples.index = samples.index.get_level_values(1)\n",
    "\n",
    "    # If you don't change it then you'll have a multiindex with level 0\n",
    "    # being the class and level 1 being the row in `data` where\n",
    "    # the sample came from.\n",
    "\n",
    "    return samples\n",
    "\n",
    "train_race_df = bootstrap(race_df,freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a5170b9-fdde-4bab-a556-aef32a6ba9d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a5170b9-fdde-4bab-a556-aef32a6ba9d3",
    "outputId": "610ca5f0-b17d-493a-bcd9-7d89835b06ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b03167e-21d3-4ebf-9448-598a9f5012c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b03167e-21d3-4ebf-9448-598a9f5012c0",
    "outputId": "4369da1e-ddad-4d2c-87b7-1088e0f328f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_race_df = race_df.drop(index = train_race_df.index, axis = 0)\n",
    "test_freq = pd.DataFrame({'label':[0, 1, 2],\n",
    "                     'nostoextract':[10000, 10000, 10000], })\n",
    "test_race_df = bootstrap(race_df,test_freq)\n",
    "len(test_race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25be56ee-be99-4ae3-b09f-5416f029ae40",
   "metadata": {
    "id": "25be56ee-be99-4ae3-b09f-5416f029ae40"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_race_df['text'], train_race_df['label'], test_size=0.3, stratify=train_race_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffff85e-7228-49fd-bafe-6144f463358a",
   "metadata": {
    "id": "3ffff85e-7228-49fd-bafe-6144f463358a"
   },
   "source": [
    "### Race prediction using pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "_2chyI5dlro6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2chyI5dlro6",
    "outputId": "a3aa23d1-336d-4f42-8021-74ced58f63f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 4.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 622 kB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 67.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 63.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 71.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
      "ERROR: unknown command \"insrall\" - maybe you meant \"install\"\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip insrall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f423886f-9ed3-4c25-a8f3-fbd22d328e61",
   "metadata": {
    "id": "f423886f-9ed3-4c25-a8f3-fbd22d328e61"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95ef7cf0-60c9-44bf-93ba-845f89305522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249,
     "referenced_widgets": [
      "6101ac3311af4fa395780c83077675ed",
      "987f0ad58d5b4ca8bd45c7376c6bb4fc",
      "d8e09e2e137246f793c92e27e5c34e52",
      "c2911c081e474a948b2e6b3144a1e6db",
      "0679bd5458874432818bc3e46d3ac5e8",
      "7f593181e8a74380909f9c2251969454",
      "93234e2a73124024a8383cbe1cee82df",
      "77bbc3041d9647b0bc8fcf6c1a7c5375",
      "a699aef53c784a07bc3e25bf25db9c9c",
      "8f193c13877646bbb64cf1f5f22215a2",
      "1e317f68a9d64f3e9f745f417c175e63",
      "78bef31f7f8540fa982082eade85621a",
      "5ac888a08d3f45718cb75b7f6e3a0515",
      "40ceb3f3776d4961ada95c7c9ad058a2",
      "18da0750565443e284a06add1eb5ca61",
      "c4d08bfa2bb849cab38cf803bd4a1a32",
      "6ab3e58481d2431781f94e152a2ba768",
      "3547985f3d024fde81a7c77a134b2eb0",
      "f4bd229c258345ca808684db70462725",
      "bc142249e80f4e55b570802c1ba7419f",
      "06862e88a1814bd1a7a8e6b6d1674808",
      "5e1885044b64435d8d2441b74bdfedb1",
      "e0593e42aa814bc99763474f374dcd88",
      "f121048473d446678bc1268b4fbef7b6",
      "fc137aecb4ca4e16a18e8a7c656077bb",
      "162fa557cd7e4cf0b9f2975b099d7965",
      "746ea0d171ff4bc5a60837bbbc7d50d4",
      "f7069296905f48f69a7783a99e8f3b5a",
      "c0150d2cc7ad431dbf224045a68d6dd7",
      "86def1113bc54b23ae403972d11d1f48",
      "6315bcf2f1a54f54b33c6af4a5045b23",
      "d6c7e8020cda4ebbbd6dc0f320376edd",
      "5378c9ab43df48089ddb904dc8c9bad8",
      "de0684b2ff3d42adbd5cd3a4aac5fce5",
      "e583c81425fb4af9b19409848c05f93f",
      "f7b50081107e496d9151d6c77b89137c",
      "4c5236d8f8614c25b4068110f5183bce",
      "80567a661e164765854c100dd7a25402",
      "1a8e28a4b7a54f9f8a062ddb968df15e",
      "f6789f9ceff44cc49aee6b27a639b314",
      "c6e7e786b1bd41b7ad1813631e1401f8",
      "84f8eef1868948ea9bb5999857819add",
      "3b9db195a7764c37b09f9486ee565eaa",
      "f092f9507cff4622afb29d2dc85cc0eb",
      "66a4c824a8414325aa1858d4cc6eb51c",
      "d15c713cf459431ab0113aec9d7770b9",
      "fc909d6d81b64f10b4566eb3055da293",
      "5e3ca8f41c8443dda965c9a68dbcf5f0",
      "2e4194aaa2954de2b3c7e4fbaa93be09",
      "b725c238ff724389be61469dae3b32ab",
      "7b39918f300a4a159a4d7d50b0394c24",
      "1088e40315ef4b1e842b06ddd84e7f7a",
      "f9d8ae23c72443ac80880bb5a30992e9",
      "bbef56eba64d4dd8a510c6286a3dc064",
      "5a31ce64c1f34f6e9ff545b2641f4d97"
     ]
    },
    "id": "95ef7cf0-60c9-44bf-93ba-845f89305522",
    "outputId": "42dfe5b7-a8d6-4a5e-a4ff-2d0d59202629"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6101ac3311af4fa395780c83077675ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bef31f7f8540fa982082eade85621a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0593e42aa814bc99763474f374dcd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0684b2ff3d42adbd5cd3a4aac5fce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a4c824a8414325aa1858d4cc6eb51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-cased', return_dict=False)\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c43b5d9-9dbc-44f6-ad22-5e3f733b468c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "9c43b5d9-9dbc-44f6-ad22-5e3f733b468c",
    "outputId": "d4455a2e-ddf6-4bda-8508-5df97f8fe0fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f73b0bce610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in race_df['text']]\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "714b0b76-6a3c-4eb4-ad9c-34d260673569",
   "metadata": {
    "id": "714b0b76-6a3c-4eb4-ad9c-34d260673569"
   },
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train.tolist(), \n",
    "    max_length = 25,\n",
    "    padding='max_length', \n",
    "    truncation=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67da9856-1597-43ee-852e-047499e7cd7e",
   "metadata": {
    "id": "67da9856-1597-43ee-852e-047499e7cd7e"
   },
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    X_val.tolist(), \n",
    "    max_length = 25,\n",
    "    padding='max_length', \n",
    "    truncation=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "274e7b2b-f7fb-4cbd-af83-e4dd2fcfd713",
   "metadata": {
    "id": "274e7b2b-f7fb-4cbd-af83-e4dd2fcfd713"
   },
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_race_df['text'].tolist(),\n",
    "    max_length = 25,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed9931a-7447-4257-b068-7f019a1f0637",
   "metadata": {
    "id": "4ed9931a-7447-4257-b068-7f019a1f0637"
   },
   "outputs": [],
   "source": [
    "# Formatting Ys turn [0, 1, 2, 0, 1, 1] to [[1,0,0], [0,1,0], [0, 0, 1], ...]\n",
    "def label_y2mat(y_ls):\n",
    "    y_mat = np.zeros((len(y_ls), 3))\n",
    "\n",
    "    for idx, v in enumerate(y_ls):\n",
    "        v = int(v)\n",
    "        y_mat[idx][v] = 1\n",
    "\n",
    "    return y_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ab1d47-e1b4-4834-94cb-aa7c7362d45a",
   "metadata": {
    "id": "f2ab1d47-e1b4-4834-94cb-aa7c7362d45a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(label_y2mat(y_train.tolist()), dtype=torch.float32)\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(label_y2mat(y_val.tolist()), dtype=torch.float32)\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(label_y2mat(test_race_df['label'].tolist()), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ba81b2-46b9-4814-b796-5855444c96a6",
   "metadata": {
    "id": "03ba81b2-46b9-4814-b796-5855444c96a6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635ae0fe-b3fa-47ff-bea0-e3fbf696778a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "635ae0fe-b3fa-47ff-bea0-e3fbf696778a",
    "outputId": "4aca0ad2-8730-4614-f24a-c6a28cbf77bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.66666667 1.11111111 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y = y_train)\n",
    "print(\"Class Weights:\",class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72496880-3af4-4a6d-8318-9653a208dacc",
   "metadata": {
    "id": "72496880-3af4-4a6d-8318-9653a208dacc"
   },
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "# number of training epochs\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb754835-3b2d-4f39-95ad-31320390be8a",
   "metadata": {
    "id": "eb754835-3b2d-4f39-95ad-31320390be8a"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert, n_classes: int,):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(768, self.bert.config.hidden_size)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.criterion = nn.BCELoss(weight=weights)\n",
    "\n",
    "        \n",
    "        \n",
    "    # define the forward pass    \n",
    "    def forward(self, sent_id, mask, labels = None):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "829e2783-022f-4dfd-97cd-6167b44caf28",
   "metadata": {
    "id": "829e2783-022f-4dfd-97cd-6167b44caf28"
   },
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert, 3)\n",
    "# push the model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6170f61b-4e63-4c5a-bedf-4a0280084f9b",
   "metadata": {
    "id": "6170f61b-4e63-4c5a-bedf-4a0280084f9b"
   },
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "lr = 1e-5)          # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1faea478-2eb7-454d-80a7-b112214d36e1",
   "metadata": {
    "id": "1faea478-2eb7-454d-80a7-b112214d36e1"
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "        \n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "        # compute the loss between actual and predicted values\n",
    "\n",
    "        loss = model.criterion(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "        \n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2673216-479f-493a-ad75-87c620cd649c",
   "metadata": {
    "id": "a2673216-479f-493a-ad75-87c620cd649c"
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = model.criterion(preds,labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "        \n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ef8cbe3-b233-46a2-b518-77e5b3944521",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7ef8cbe3-b233-46a2-b518-77e5b3944521",
    "outputId": "78de878a-1185-4edc-e659-952f5a1666ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 8\n",
      "  Batch    50  of  2,188.\n",
      "  Batch   100  of  2,188.\n",
      "  Batch   150  of  2,188.\n",
      "  Batch   200  of  2,188.\n",
      "  Batch   250  of  2,188.\n",
      "  Batch   300  of  2,188.\n",
      "  Batch   350  of  2,188.\n",
      "  Batch   400  of  2,188.\n",
      "  Batch   450  of  2,188.\n",
      "  Batch   500  of  2,188.\n",
      "  Batch   550  of  2,188.\n",
      "  Batch   600  of  2,188.\n",
      "  Batch   650  of  2,188.\n",
      "  Batch   700  of  2,188.\n",
      "  Batch   750  of  2,188.\n",
      "  Batch   800  of  2,188.\n",
      "  Batch   850  of  2,188.\n",
      "  Batch   900  of  2,188.\n",
      "  Batch   950  of  2,188.\n",
      "  Batch 1,000  of  2,188.\n",
      "  Batch 1,050  of  2,188.\n",
      "  Batch 1,100  of  2,188.\n",
      "  Batch 1,150  of  2,188.\n",
      "  Batch 1,200  of  2,188.\n",
      "  Batch 1,250  of  2,188.\n",
      "  Batch 1,300  of  2,188.\n",
      "  Batch 1,350  of  2,188.\n",
      "  Batch 1,400  of  2,188.\n",
      "  Batch 1,450  of  2,188.\n",
      "  Batch 1,500  of  2,188.\n",
      "  Batch 1,550  of  2,188.\n",
      "  Batch 1,600  of  2,188.\n",
      "  Batch 1,650  of  2,188.\n",
      "  Batch 1,700  of  2,188.\n",
      "  Batch 1,750  of  2,188.\n",
      "  Batch 1,800  of  2,188.\n",
      "  Batch 1,850  of  2,188.\n",
      "  Batch 1,900  of  2,188.\n",
      "  Batch 1,950  of  2,188.\n",
      "  Batch 2,000  of  2,188.\n",
      "  Batch 2,050  of  2,188.\n",
      "  Batch 2,100  of  2,188.\n",
      "  Batch 2,150  of  2,188.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    938.\n",
      "  Batch   100  of    938.\n",
      "  Batch   150  of    938.\n",
      "  Batch   200  of    938.\n",
      "  Batch   250  of    938.\n",
      "  Batch   300  of    938.\n",
      "  Batch   350  of    938.\n",
      "  Batch   400  of    938.\n",
      "  Batch   450  of    938.\n",
      "  Batch   500  of    938.\n",
      "  Batch   550  of    938.\n",
      "  Batch   600  of    938.\n",
      "  Batch   650  of    938.\n",
      "  Batch   700  of    938.\n",
      "  Batch   750  of    938.\n",
      "  Batch   800  of    938.\n",
      "  Batch   850  of    938.\n",
      "  Batch   900  of    938.\n",
      "\n",
      "Training Loss: 0.654\n",
      "Validation Loss: 0.637\n",
      "\n",
      " Epoch 2 / 8\n",
      "  Batch    50  of  2,188.\n",
      "  Batch   100  of  2,188.\n",
      "  Batch   150  of  2,188.\n",
      "  Batch   200  of  2,188.\n",
      "  Batch   250  of  2,188.\n",
      "  Batch   300  of  2,188.\n",
      "  Batch   350  of  2,188.\n",
      "  Batch   400  of  2,188.\n",
      "  Batch   450  of  2,188.\n",
      "  Batch   500  of  2,188.\n",
      "  Batch   550  of  2,188.\n",
      "  Batch   600  of  2,188.\n",
      "  Batch   650  of  2,188.\n",
      "  Batch   700  of  2,188.\n",
      "  Batch   750  of  2,188.\n",
      "  Batch   800  of  2,188.\n",
      "  Batch   850  of  2,188.\n",
      "  Batch   900  of  2,188.\n",
      "  Batch   950  of  2,188.\n",
      "  Batch 1,000  of  2,188.\n",
      "  Batch 1,050  of  2,188.\n",
      "  Batch 1,100  of  2,188.\n",
      "  Batch 1,150  of  2,188.\n",
      "  Batch 1,200  of  2,188.\n",
      "  Batch 1,250  of  2,188.\n",
      "  Batch 1,300  of  2,188.\n",
      "  Batch 1,350  of  2,188.\n",
      "  Batch 1,400  of  2,188.\n",
      "  Batch 1,450  of  2,188.\n",
      "  Batch 1,500  of  2,188.\n",
      "  Batch 1,550  of  2,188.\n",
      "  Batch 1,600  of  2,188.\n",
      "  Batch 1,650  of  2,188.\n",
      "  Batch 1,700  of  2,188.\n",
      "  Batch 1,750  of  2,188.\n",
      "  Batch 1,800  of  2,188.\n",
      "  Batch 1,850  of  2,188.\n",
      "  Batch 1,900  of  2,188.\n",
      "  Batch 1,950  of  2,188.\n",
      "  Batch 2,000  of  2,188.\n",
      "  Batch 2,050  of  2,188.\n",
      "  Batch 2,100  of  2,188.\n",
      "  Batch 2,150  of  2,188.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    938.\n",
      "  Batch   100  of    938.\n",
      "  Batch   150  of    938.\n",
      "  Batch   200  of    938.\n",
      "  Batch   250  of    938.\n",
      "  Batch   300  of    938.\n",
      "  Batch   350  of    938.\n",
      "  Batch   400  of    938.\n",
      "  Batch   450  of    938.\n",
      "  Batch   500  of    938.\n",
      "  Batch   550  of    938.\n",
      "  Batch   600  of    938.\n",
      "  Batch   650  of    938.\n",
      "  Batch   700  of    938.\n",
      "  Batch   750  of    938.\n",
      "  Batch   800  of    938.\n",
      "  Batch   850  of    938.\n",
      "  Batch   900  of    938.\n",
      "\n",
      "Training Loss: 0.614\n",
      "Validation Loss: 0.627\n",
      "\n",
      " Epoch 3 / 8\n",
      "  Batch    50  of  2,188.\n",
      "  Batch   100  of  2,188.\n",
      "  Batch   150  of  2,188.\n",
      "  Batch   200  of  2,188.\n",
      "  Batch   250  of  2,188.\n",
      "  Batch   300  of  2,188.\n",
      "  Batch   350  of  2,188.\n",
      "  Batch   400  of  2,188.\n",
      "  Batch   450  of  2,188.\n",
      "  Batch   500  of  2,188.\n",
      "  Batch   550  of  2,188.\n",
      "  Batch   600  of  2,188.\n",
      "  Batch   650  of  2,188.\n",
      "  Batch   700  of  2,188.\n",
      "  Batch   750  of  2,188.\n",
      "  Batch   800  of  2,188.\n",
      "  Batch   850  of  2,188.\n",
      "  Batch   900  of  2,188.\n",
      "  Batch   950  of  2,188.\n",
      "  Batch 1,000  of  2,188.\n",
      "  Batch 1,050  of  2,188.\n",
      "  Batch 1,100  of  2,188.\n",
      "  Batch 1,150  of  2,188.\n",
      "  Batch 1,200  of  2,188.\n",
      "  Batch 1,250  of  2,188.\n",
      "  Batch 1,300  of  2,188.\n",
      "  Batch 1,350  of  2,188.\n",
      "  Batch 1,400  of  2,188.\n",
      "  Batch 1,450  of  2,188.\n",
      "  Batch 1,500  of  2,188.\n",
      "  Batch 1,550  of  2,188.\n",
      "  Batch 1,600  of  2,188.\n",
      "  Batch 1,650  of  2,188.\n",
      "  Batch 1,700  of  2,188.\n",
      "  Batch 1,750  of  2,188.\n",
      "  Batch 1,800  of  2,188.\n",
      "  Batch 1,850  of  2,188.\n",
      "  Batch 1,900  of  2,188.\n",
      "  Batch 1,950  of  2,188.\n",
      "  Batch 2,000  of  2,188.\n",
      "  Batch 2,050  of  2,188.\n",
      "  Batch 2,100  of  2,188.\n",
      "  Batch 2,150  of  2,188.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    938.\n",
      "  Batch   100  of    938.\n",
      "  Batch   150  of    938.\n",
      "  Batch   200  of    938.\n",
      "  Batch   250  of    938.\n",
      "  Batch   300  of    938.\n",
      "  Batch   350  of    938.\n",
      "  Batch   400  of    938.\n",
      "  Batch   450  of    938.\n",
      "  Batch   500  of    938.\n",
      "  Batch   550  of    938.\n",
      "  Batch   600  of    938.\n",
      "  Batch   650  of    938.\n",
      "  Batch   700  of    938.\n",
      "  Batch   750  of    938.\n",
      "  Batch   800  of    938.\n",
      "  Batch   850  of    938.\n",
      "  Batch   900  of    938.\n",
      "\n",
      "Training Loss: 0.546\n",
      "Validation Loss: 0.652\n",
      "\n",
      " Epoch 4 / 8\n",
      "  Batch    50  of  2,188.\n",
      "  Batch   100  of  2,188.\n",
      "  Batch   150  of  2,188.\n",
      "  Batch   200  of  2,188.\n",
      "  Batch   250  of  2,188.\n",
      "  Batch   300  of  2,188.\n",
      "  Batch   350  of  2,188.\n",
      "  Batch   400  of  2,188.\n",
      "  Batch   450  of  2,188.\n",
      "  Batch   500  of  2,188.\n",
      "  Batch   550  of  2,188.\n",
      "  Batch   600  of  2,188.\n",
      "  Batch   650  of  2,188.\n",
      "  Batch   700  of  2,188.\n",
      "  Batch   750  of  2,188.\n",
      "  Batch   800  of  2,188.\n",
      "  Batch   850  of  2,188.\n",
      "  Batch   900  of  2,188.\n",
      "  Batch   950  of  2,188.\n",
      "  Batch 1,000  of  2,188.\n",
      "  Batch 1,050  of  2,188.\n",
      "  Batch 1,100  of  2,188.\n",
      "  Batch 1,150  of  2,188.\n",
      "  Batch 1,200  of  2,188.\n",
      "  Batch 1,250  of  2,188.\n",
      "  Batch 1,300  of  2,188.\n",
      "  Batch 1,350  of  2,188.\n",
      "  Batch 1,400  of  2,188.\n",
      "  Batch 1,450  of  2,188.\n",
      "  Batch 1,500  of  2,188.\n",
      "  Batch 1,550  of  2,188.\n",
      "  Batch 1,600  of  2,188.\n",
      "  Batch 1,650  of  2,188.\n",
      "  Batch 1,700  of  2,188.\n",
      "  Batch 1,750  of  2,188.\n",
      "  Batch 1,800  of  2,188.\n",
      "  Batch 1,850  of  2,188.\n",
      "  Batch 1,900  of  2,188.\n",
      "  Batch 1,950  of  2,188.\n",
      "  Batch 2,000  of  2,188.\n",
      "  Batch 2,050  of  2,188.\n",
      "  Batch 2,100  of  2,188.\n",
      "  Batch 2,150  of  2,188.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    938.\n",
      "  Batch   100  of    938.\n",
      "  Batch   150  of    938.\n",
      "  Batch   200  of    938.\n",
      "  Batch   250  of    938.\n",
      "  Batch   300  of    938.\n",
      "  Batch   350  of    938.\n",
      "  Batch   400  of    938.\n",
      "  Batch   450  of    938.\n",
      "  Batch   500  of    938.\n",
      "  Batch   550  of    938.\n",
      "  Batch   600  of    938.\n",
      "  Batch   650  of    938.\n",
      "  Batch   700  of    938.\n",
      "  Batch   750  of    938.\n",
      "  Batch   800  of    938.\n",
      "  Batch   850  of    938.\n",
      "  Batch   900  of    938.\n",
      "\n",
      "Training Loss: 0.454\n",
      "Validation Loss: 0.733\n",
      "\n",
      " Epoch 5 / 8\n",
      "  Batch    50  of  2,188.\n",
      "  Batch   100  of  2,188.\n",
      "  Batch   150  of  2,188.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8e02697d9820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c6d29511fa50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# model predictions are stored on GPU. So, push it to CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "nYapvkitc_sk",
   "metadata": {
    "id": "nYapvkitc_sk"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00f8d0e9-a8b7-46ef-ae1f-94254cc87611",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "00f8d0e9-a8b7-46ef-ae1f-94254cc87611",
    "outputId": "e8ab4dc7-906b-4927-f978-071bf5adad54"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2ad50894c957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-1d518a3d3d68>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask, labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# define the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m                 )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 860.00 MiB (GPU 0; 15.90 GiB total capacity; 14.52 GiB already allocated; 101.75 MiB free; 14.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()\n",
    "\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "y_test = np.argmax(test_y, axis = 1)\n",
    "\n",
    "print(confusion_matrix(y_test, preds, normalize='all'))\n",
    "precision_recall_fscore_support(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1iXruhPn9Zp-",
   "metadata": {
    "id": "1iXruhPn9Zp-"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, preds, normalize='true'))\n",
    "precision_recall_fscore_support(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sLrhflTvtGMD",
   "metadata": {
    "id": "sLrhflTvtGMD"
   },
   "source": [
    "Below are previous score with BCELoss with dropout rate 0.1 \n",
    "with training set 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SP3L9EQUz9nH",
   "metadata": {
    "id": "SP3L9EQUz9nH"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_AjtDSFgp8OM",
   "metadata": {
    "id": "_AjtDSFgp8OM"
   },
   "outputs": [],
   "source": [
    "test_y\n",
    "y_test = np.argmax(test_y, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cFttqCt5qBK5",
   "metadata": {
    "id": "cFttqCt5qBK5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BTobH_68qsJl",
   "metadata": {
    "id": "BTobH_68qsJl"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JEI1BIxZqyCU",
   "metadata": {
    "id": "JEI1BIxZqyCU"
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dYaRdFbVsCCr",
   "metadata": {
    "id": "dYaRdFbVsCCr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bert_race.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0679bd5458874432818bc3e46d3ac5e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e317f68a9d64f3e9f745f417c175e63",
      "placeholder": "​",
      "style": "IPY_MODEL_8f193c13877646bbb64cf1f5f22215a2",
      "value": " 570/570 [00:00&lt;00:00, 23.0kB/s]"
     }
    },
    "06862e88a1814bd1a7a8e6b6d1674808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1088e40315ef4b1e842b06ddd84e7f7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "162fa557cd7e4cf0b9f2975b099d7965": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6315bcf2f1a54f54b33c6af4a5045b23",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86def1113bc54b23ae403972d11d1f48",
      "value": 213450
     }
    },
    "18da0750565443e284a06add1eb5ca61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc142249e80f4e55b570802c1ba7419f",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4bd229c258345ca808684db70462725",
      "value": 435779157
     }
    },
    "1a8e28a4b7a54f9f8a062ddb968df15e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e317f68a9d64f3e9f745f417c175e63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e4194aaa2954de2b3c7e4fbaa93be09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a31ce64c1f34f6e9ff545b2641f4d97",
      "placeholder": "​",
      "style": "IPY_MODEL_bbef56eba64d4dd8a510c6286a3dc064",
      "value": " 29.0/29.0 [00:00&lt;00:00, 1.27kB/s]"
     }
    },
    "3547985f3d024fde81a7c77a134b2eb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b9db195a7764c37b09f9486ee565eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40ceb3f3776d4961ada95c7c9ad058a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3547985f3d024fde81a7c77a134b2eb0",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab3e58481d2431781f94e152a2ba768",
      "value": "Downloading: 100%"
     }
    },
    "4c5236d8f8614c25b4068110f5183bce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84f8eef1868948ea9bb5999857819add",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6e7e786b1bd41b7ad1813631e1401f8",
      "value": 435797
     }
    },
    "5378c9ab43df48089ddb904dc8c9bad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a31ce64c1f34f6e9ff545b2641f4d97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ac888a08d3f45718cb75b7f6e3a0515": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1885044b64435d8d2441b74bdfedb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e3ca8f41c8443dda965c9a68dbcf5f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9d8ae23c72443ac80880bb5a30992e9",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1088e40315ef4b1e842b06ddd84e7f7a",
      "value": 29
     }
    },
    "6101ac3311af4fa395780c83077675ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8e09e2e137246f793c92e27e5c34e52",
       "IPY_MODEL_c2911c081e474a948b2e6b3144a1e6db",
       "IPY_MODEL_0679bd5458874432818bc3e46d3ac5e8"
      ],
      "layout": "IPY_MODEL_987f0ad58d5b4ca8bd45c7376c6bb4fc"
     }
    },
    "6315bcf2f1a54f54b33c6af4a5045b23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66a4c824a8414325aa1858d4cc6eb51c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc909d6d81b64f10b4566eb3055da293",
       "IPY_MODEL_5e3ca8f41c8443dda965c9a68dbcf5f0",
       "IPY_MODEL_2e4194aaa2954de2b3c7e4fbaa93be09"
      ],
      "layout": "IPY_MODEL_d15c713cf459431ab0113aec9d7770b9"
     }
    },
    "6ab3e58481d2431781f94e152a2ba768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "746ea0d171ff4bc5a60837bbbc7d50d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5378c9ab43df48089ddb904dc8c9bad8",
      "placeholder": "​",
      "style": "IPY_MODEL_d6c7e8020cda4ebbbd6dc0f320376edd",
      "value": " 208k/208k [00:00&lt;00:00, 240kB/s]"
     }
    },
    "77bbc3041d9647b0bc8fcf6c1a7c5375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78bef31f7f8540fa982082eade85621a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40ceb3f3776d4961ada95c7c9ad058a2",
       "IPY_MODEL_18da0750565443e284a06add1eb5ca61",
       "IPY_MODEL_c4d08bfa2bb849cab38cf803bd4a1a32"
      ],
      "layout": "IPY_MODEL_5ac888a08d3f45718cb75b7f6e3a0515"
     }
    },
    "7b39918f300a4a159a4d7d50b0394c24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f593181e8a74380909f9c2251969454": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80567a661e164765854c100dd7a25402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f092f9507cff4622afb29d2dc85cc0eb",
      "placeholder": "​",
      "style": "IPY_MODEL_3b9db195a7764c37b09f9486ee565eaa",
      "value": " 426k/426k [00:00&lt;00:00, 636kB/s]"
     }
    },
    "84f8eef1868948ea9bb5999857819add": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86def1113bc54b23ae403972d11d1f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f193c13877646bbb64cf1f5f22215a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93234e2a73124024a8383cbe1cee82df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "987f0ad58d5b4ca8bd45c7376c6bb4fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a699aef53c784a07bc3e25bf25db9c9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b725c238ff724389be61469dae3b32ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbef56eba64d4dd8a510c6286a3dc064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc142249e80f4e55b570802c1ba7419f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0150d2cc7ad431dbf224045a68d6dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2911c081e474a948b2e6b3144a1e6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a699aef53c784a07bc3e25bf25db9c9c",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77bbc3041d9647b0bc8fcf6c1a7c5375",
      "value": 570
     }
    },
    "c4d08bfa2bb849cab38cf803bd4a1a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e1885044b64435d8d2441b74bdfedb1",
      "placeholder": "​",
      "style": "IPY_MODEL_06862e88a1814bd1a7a8e6b6d1674808",
      "value": " 416M/416M [00:07&lt;00:00, 59.1MB/s]"
     }
    },
    "c6e7e786b1bd41b7ad1813631e1401f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15c713cf459431ab0113aec9d7770b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c7e8020cda4ebbbd6dc0f320376edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8e09e2e137246f793c92e27e5c34e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93234e2a73124024a8383cbe1cee82df",
      "placeholder": "​",
      "style": "IPY_MODEL_7f593181e8a74380909f9c2251969454",
      "value": "Downloading: 100%"
     }
    },
    "de0684b2ff3d42adbd5cd3a4aac5fce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7b50081107e496d9151d6c77b89137c",
       "IPY_MODEL_4c5236d8f8614c25b4068110f5183bce",
       "IPY_MODEL_80567a661e164765854c100dd7a25402"
      ],
      "layout": "IPY_MODEL_e583c81425fb4af9b19409848c05f93f"
     }
    },
    "e0593e42aa814bc99763474f374dcd88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc137aecb4ca4e16a18e8a7c656077bb",
       "IPY_MODEL_162fa557cd7e4cf0b9f2975b099d7965",
       "IPY_MODEL_746ea0d171ff4bc5a60837bbbc7d50d4"
      ],
      "layout": "IPY_MODEL_f121048473d446678bc1268b4fbef7b6"
     }
    },
    "e583c81425fb4af9b19409848c05f93f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f092f9507cff4622afb29d2dc85cc0eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f121048473d446678bc1268b4fbef7b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4bd229c258345ca808684db70462725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6789f9ceff44cc49aee6b27a639b314": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7069296905f48f69a7783a99e8f3b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7b50081107e496d9151d6c77b89137c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6789f9ceff44cc49aee6b27a639b314",
      "placeholder": "​",
      "style": "IPY_MODEL_1a8e28a4b7a54f9f8a062ddb968df15e",
      "value": "Downloading: 100%"
     }
    },
    "f9d8ae23c72443ac80880bb5a30992e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc137aecb4ca4e16a18e8a7c656077bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0150d2cc7ad431dbf224045a68d6dd7",
      "placeholder": "​",
      "style": "IPY_MODEL_f7069296905f48f69a7783a99e8f3b5a",
      "value": "Downloading: 100%"
     }
    },
    "fc909d6d81b64f10b4566eb3055da293": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b39918f300a4a159a4d7d50b0394c24",
      "placeholder": "​",
      "style": "IPY_MODEL_b725c238ff724389be61469dae3b32ab",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
